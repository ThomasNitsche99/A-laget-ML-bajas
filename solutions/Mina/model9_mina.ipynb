{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preprocessing the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>vesselId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>131115</th>\n",
       "      <td>2024-01-12 14:07:47</td>\n",
       "      <td>7.50361</td>\n",
       "      <td>77.58340</td>\n",
       "      <td>61e9f38eb937134a3c4bfd8b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131279</th>\n",
       "      <td>2024-01-12 14:31:00</td>\n",
       "      <td>7.57302</td>\n",
       "      <td>77.49505</td>\n",
       "      <td>61e9f38eb937134a3c4bfd8b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131514</th>\n",
       "      <td>2024-01-12 14:57:23</td>\n",
       "      <td>7.65043</td>\n",
       "      <td>77.39404</td>\n",
       "      <td>61e9f38eb937134a3c4bfd8b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131696</th>\n",
       "      <td>2024-01-12 15:18:48</td>\n",
       "      <td>7.71275</td>\n",
       "      <td>77.31394</td>\n",
       "      <td>61e9f38eb937134a3c4bfd8b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131885</th>\n",
       "      <td>2024-01-12 15:39:47</td>\n",
       "      <td>7.77191</td>\n",
       "      <td>77.23585</td>\n",
       "      <td>61e9f38eb937134a3c4bfd8b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       time  latitude  longitude                  vesselId\n",
       "131115  2024-01-12 14:07:47   7.50361   77.58340  61e9f38eb937134a3c4bfd8b\n",
       "131279  2024-01-12 14:31:00   7.57302   77.49505  61e9f38eb937134a3c4bfd8b\n",
       "131514  2024-01-12 14:57:23   7.65043   77.39404  61e9f38eb937134a3c4bfd8b\n",
       "131696  2024-01-12 15:18:48   7.71275   77.31394  61e9f38eb937134a3c4bfd8b\n",
       "131885  2024-01-12 15:39:47   7.77191   77.23585  61e9f38eb937134a3c4bfd8b"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ais = pd.read_csv('/Users/minasjovik/Projects/machine-learning-project/A-laget-ML-bajas/data/raw/ais_train.csv', sep='|')\n",
    "\n",
    "\n",
    "#Drop columns we don't want to use\n",
    "ais = ais.drop(['etaRaw','cog', 'rot', 'sog', 'portId', 'heading', 'navstat'], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "#Sort training data by vesselId and time\n",
    "ais = ais.sort_values(by=['vesselId','time'])\n",
    "\n",
    "#Print \n",
    "ais.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Transform time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "ais['time'] = pd.to_datetime(ais['time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### How long have the vessel been measured?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "ais['time_measured'] = ais.groupby('vesselId')['time'].diff().dt.total_seconds()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Creating training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_data(df: pd.DataFrame, N_KEEP_PAST: int) -> pd.DataFrame:\n",
    "    data_rows = []  # List to store data rows\n",
    "    # Get unique vessel IDs from the DataFrame\n",
    "    unique_vessels = df['vesselId'].unique()\n",
    "\n",
    "    # Iterate over each unique vessel\n",
    "    for vessel in tqdm(unique_vessels):\n",
    "        # Filter data for the current vessel and sort by time\n",
    "        vessel_data = df[df['vesselId'] == vessel].sort_values(by='time').reset_index(drop=True)\n",
    "        total_rows = len(vessel_data)\n",
    "        \n",
    "        # Skip vessels with insufficient data\n",
    "        if total_rows <= N_KEEP_PAST:\n",
    "            continue\n",
    "\n",
    "        # Process each record starting from N_KEEP_PAST\n",
    "        for index in range(N_KEEP_PAST, total_rows):\n",
    "            current_record = vessel_data.iloc[index]\n",
    "            previous_records = vessel_data.iloc[index - N_KEEP_PAST:index]\n",
    "\n",
    "            # Initialize a dictionary to hold the feature values and target\n",
    "            feature_row = {\n",
    "                'vesselId': vessel,\n",
    "                'target_lat': current_record['latitude'],\n",
    "                'target_lon': current_record['longitude'],\n",
    "                'target_time': current_record['time'],\n",
    "                'time_measured': current_record['time_measured']\n",
    "             \n",
    "            }\n",
    "\n",
    "            # Loop through past records to collect features\n",
    "            for j, past_record in previous_records.iterrows():\n",
    "                feature_row[f'lat_{j - (index - N_KEEP_PAST)}'] = past_record['latitude']\n",
    "                feature_row[f'lon_{j - (index - N_KEEP_PAST)}'] = past_record['longitude']\n",
    "\n",
    "            # Append the feature row to the data list\n",
    "            data_rows.append(feature_row)\n",
    "\n",
    "    # Convert the list of feature rows to a DataFrame\n",
    "    return pd.DataFrame(data_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 688/688 [06:30<00:00,  1.76it/s]\n"
     ]
    }
   ],
   "source": [
    "processed_train = create_training_data(ais, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Store training data as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_train.to_csv('/Users/minasjovik/Projects/machine-learning-project/A-laget-ML-bajas/solutions/Mina/processed_train_mina.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Preprocessing the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Load test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>vesselId</th>\n",
       "      <th>time</th>\n",
       "      <th>scaling_factor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>61e9f3aeb937134a3c4bfe3d</td>\n",
       "      <td>2024-05-08 00:03:16</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>61e9f473b937134a3c4c02df</td>\n",
       "      <td>2024-05-08 00:06:17</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>61e9f469b937134a3c4c029b</td>\n",
       "      <td>2024-05-08 00:10:02</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>61e9f45bb937134a3c4c0221</td>\n",
       "      <td>2024-05-08 00:10:34</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>61e9f38eb937134a3c4bfd8d</td>\n",
       "      <td>2024-05-08 00:12:27</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                  vesselId                time  scaling_factor\n",
       "0   0  61e9f3aeb937134a3c4bfe3d 2024-05-08 00:03:16             0.3\n",
       "1   1  61e9f473b937134a3c4c02df 2024-05-08 00:06:17             0.3\n",
       "2   2  61e9f469b937134a3c4c029b 2024-05-08 00:10:02             0.3\n",
       "3   3  61e9f45bb937134a3c4c0221 2024-05-08 00:10:34             0.3\n",
       "4   4  61e9f38eb937134a3c4bfd8d 2024-05-08 00:12:27             0.3"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = pd.read_csv('/Users/minasjovik/Projects/machine-learning-project/A-laget-ML-bajas/data/raw/ais_test.csv')\n",
    "\n",
    "test_dataset['time'] = pd.to_datetime(test_dataset['time'])\n",
    "\n",
    "test_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def create_test_data(train_df: pd.DataFrame, test_df: pd.DataFrame, N_KEEP_PAST: int) -> pd.DataFrame:\n",
    "    data_rows = []  # List to collect all the data rows\n",
    "    unique_vessels = test_df['vesselId'].unique()  # Get unique vessel IDs\n",
    "\n",
    "    # Iterate over each unique vessel\n",
    "    for vessel in tqdm(unique_vessels):\n",
    "        # Filter out the train data for this vessel that is less than the max time in test data\n",
    "        vessel_train_data = train_df[train_df['vesselId'] == vessel].sort_values(by='time').reset_index(drop=True)\n",
    "       \n",
    "        # Get test data for the current vessel\n",
    "        test_vessel_data = test_df[test_df['vesselId'] == vessel]\n",
    "        \n",
    "        for _, test_row in test_vessel_data.iterrows():\n",
    "        \n",
    "            target_time = test_row['time']\n",
    "            #current_record = vessel_train_data.iloc[_]\n",
    "            \n",
    "            \n",
    "            ID = test_row['ID']\n",
    "            # Get the last N_KEEP_PAST records from the train data before the target time\n",
    "            past_data = vessel_train_data[vessel_train_data['time'] < target_time].tail(N_KEEP_PAST)\n",
    "\n",
    "            # Check if we have enough past data\n",
    "            if len(past_data) < N_KEEP_PAST:\n",
    "                continue  # Not enough past data; skip this test row\n",
    "\n",
    "            # Prepare a dictionary to hold the features\n",
    "            feature_row = {\n",
    "                'vesselId': vessel, \n",
    "                'target_time': target_time, # Only include target time\n",
    "            }\n",
    "\n",
    "            # Loop through past records to collect features\n",
    "            for j in range(N_KEEP_PAST):\n",
    "                past_record = past_data.iloc[j]\n",
    "                feature_row[f'time_measured']= past_record['time_measured']\n",
    "                feature_row[f'lat_{j}'] = past_record['latitude']\n",
    "                feature_row[f'lon_{j}'] = past_record['longitude']\n",
    "                \n",
    "\n",
    "            feature_row['vesselId'] = vessel\n",
    "            feature_row['ID'] = ID\n",
    "            \n",
    "            # Append the row to the list\n",
    "            data_rows.append(feature_row)\n",
    "\n",
    "    #Convert the list of feature rows to a DataFrame\n",
    "    return pd.DataFrame(data_rows)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 215/215 [00:44<00:00,  4.80it/s]\n"
     ]
    }
   ],
   "source": [
    "processed_test = create_test_data(ais, test_dataset, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vesselId                 object\n",
      "target_time      datetime64[ns]\n",
      "time_measured           float64\n",
      "lat_0                   float64\n",
      "lon_0                   float64\n",
      "lat_1                   float64\n",
      "lon_1                   float64\n",
      "ID                        int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(processed_test.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_test.to_csv('/Users/minasjovik/Projects/machine-learning-project/A-laget-ML-bajas/solutions/Mina/processed_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['heading_0', 'lat_0', 'lon_0', 'heading_1', 'lat_1', 'lon_1',\n",
      "       'heading_2', 'lat_2', 'lon_2', 'heading_3', 'lat_3', 'lon_3',\n",
      "       'heading_4', 'lat_4', 'lon_4'],\n",
      "      dtype='object')\n",
      "Training and predicting with model: RandomForest\n",
      "Training and predicting with model: XGBoost\n",
      "Training and predicting with model: ElasticNet\n",
      "Training and predicting with model: LightGBM\n",
      "Training and predicting with model: RandomForest\n",
      "Training and predicting with model: XGBoost\n",
      "Training and predicting with model: ElasticNet\n",
      "Training and predicting with model: LightGBM\n",
      "Training and predicting with model: RandomForest\n",
      "Training and predicting with model: XGBoost\n",
      "Training and predicting with model: ElasticNet\n",
      "Training and predicting with model: LightGBM\n",
      "Training and predicting with model: RandomForest\n",
      "Training and predicting with model: XGBoost\n",
      "Training and predicting with model: ElasticNet\n",
      "Training and predicting with model: LightGBM\n",
      "Training and predicting with model: RandomForest\n",
      "Training and predicting with model: XGBoost\n",
      "Training and predicting with model: ElasticNet\n",
      "Training and predicting with model: LightGBM\n",
      "Optimizing weights using method: Nelder-Mead\n",
      "Method: Nelder-Mead, MSE: 13.426029326600696\n",
      "Optimizing weights using method: Powell\n",
      "Method: Powell, MSE: 13.426029323809297\n",
      "Optimizing weights using method: CG\n",
      "Method: CG, MSE: 13.426029323660941\n",
      "Optimizing weights using method: BFGS\n",
      "Method: BFGS, MSE: 13.426029323660577\n",
      "Optimizing weights using method: L-BFGS-B\n",
      "Method: L-BFGS-B, MSE: 13.426029323661943\n",
      "Optimizing weights using method: TNC\n",
      "Method: TNC, MSE: 13.43208572305214\n",
      "Optimizing weights using method: SLSQP\n",
      "Method: SLSQP, MSE: 13.426029323659487\n",
      "Best optimization method: SLSQP\n",
      "Best weights:\n",
      "RandomForest: 0.0020\n",
      "XGBoost: 0.2613\n",
      "ElasticNet: 0.1251\n",
      "LightGBM: 0.6115\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from sklearn.model_selection import KFold\n",
    "# from sklearn.multioutput import MultiOutputRegressor\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.linear_model import ElasticNet\n",
    "# import xgboost as xgb\n",
    "# import lightgbm as lgb\n",
    "# from scipy.optimize import minimize\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# # Load the data\n",
    "# test_final = pd.read_csv('/Users/minasjovik/Projects/machine-learning-project/A-laget-ML-bajas/solutions/Mina/processed_test.csv')\n",
    "# final_train = pd.read_csv('/Users/minasjovik/Projects/machine-learning-project/A-laget-ML-bajas/solutions/Mina/processed_train_mina.csv')\n",
    "\n",
    "# # Define features and targets\n",
    "# features = final_train.drop(columns=['target_lat', 'target_lon', 'time_measured'])\n",
    "# targets = final_train[['target_lat', 'target_lon']]\n",
    "\n",
    "# feature_columns = features.columns\n",
    "# print(feature_columns)\n",
    "# X_test = test_final[feature_columns]\n",
    "\n",
    "# # Define the models\n",
    "# models = {\n",
    "#     'RandomForest': MultiOutputRegressor(RandomForestRegressor(n_estimators=100, random_state=42, max_depth=4, n_jobs=8)),\n",
    "#     'XGBoost': MultiOutputRegressor(xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, seed=42)),\n",
    "#     'ElasticNet': MultiOutputRegressor(ElasticNet(random_state=42)),\n",
    "#     'LightGBM': MultiOutputRegressor(lgb.LGBMRegressor(n_estimators=100, random_state=42, verbose=-1))\n",
    "# }\n",
    "\n",
    "# # Prepare arrays to hold OOF predictions and test predictions\n",
    "# n_splits = 5\n",
    "# kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# oof_preds = {model_name: np.zeros((features.shape[0], targets.shape[1])) for model_name in models}\n",
    "# test_preds = {model_name: np.zeros((X_test.shape[0], targets.shape[1], n_splits)) for model_name in models}\n",
    "\n",
    "# # Perform cross-validation and collect predictions\n",
    "# for fold, (train_idx, valid_idx) in enumerate(kf.split(features, targets)):\n",
    "#     X_train, y_train = features.iloc[train_idx], targets.iloc[train_idx]\n",
    "#     X_valid, y_valid = features.iloc[valid_idx], targets.iloc[valid_idx]\n",
    "    \n",
    "#     for model_name, model in models.items():\n",
    "#         print(f\"Training and predicting with model: {model_name}\")\n",
    "#         clf = model\n",
    "#         clf.fit(X_train, y_train)\n",
    "#         y_pred_valid = clf.predict(X_valid)\n",
    "#         y_pred_test = clf.predict(X_test)\n",
    "      \n",
    "        \n",
    "#         # Save OOF predictions\n",
    "#         oof_preds[model_name][valid_idx] = y_pred_valid\n",
    "#         # Save test predictions\n",
    "#         test_preds[model_name][:,:,fold] = y_pred_test\n",
    "\n",
    "# # Define the loss function for optimization\n",
    "# def mse_loss(weights):\n",
    "#     weights = np.array(weights)\n",
    "#     # Normalize weights to sum to 1\n",
    "#     weights = weights / np.sum(weights)\n",
    "#     # Combine OOF predictions using the weights\n",
    "#     final_oof = np.zeros_like(targets.values)\n",
    "#     for i, model_name in enumerate(models):\n",
    "#         final_oof += weights[i] * oof_preds[model_name]\n",
    "#     # Compute mean squared error\n",
    "#     mse = mean_squared_error(targets.values, final_oof)\n",
    "#     return mse\n",
    "\n",
    "# # Optimization methods to try\n",
    "# #methods = [\n",
    "# #    'Nelder-Mead', 'Powell', 'trust-constr', 'CG', 'BFGS', 'Newton-CG',\n",
    "# #    'L-BFGS-B', 'TNC', 'COBYLA', 'SLSQP', 'dogleg', 'trust-ncg',\n",
    "# #    'trust-exact', 'trust-krylov'\n",
    "# #]\n",
    "# methods = [\n",
    "#     'Nelder-Mead', 'Powell',  'CG', 'BFGS',\n",
    "#     'L-BFGS-B', 'TNC', 'SLSQP', \n",
    "# ] # 'trust-constr' is just really slow and not performing well at the this moment\n",
    "\n",
    "# # Initial weights\n",
    "# initial_weights = np.ones(len(models)) / len(models)\n",
    "\n",
    "# # Constraints and bounds\n",
    "# constraints = ({'type': 'eq', 'fun': lambda w: np.sum(w) - 1})\n",
    "# bounds = [(0, 1)] * len(models)\n",
    "\n",
    "# # Optimize weights using different methods\n",
    "# best_mse = np.inf\n",
    "# best_weights = None\n",
    "# best_method = None\n",
    "\n",
    "# for method in methods:\n",
    "#     print(f\"Optimizing weights using method: {method}\")\n",
    "#     try:\n",
    "#         if method in ['trust-constr', 'COBYLA', 'SLSQP', 'trust-ncg', 'trust-krylov', 'trust-exact']:\n",
    "#             res = minimize(mse_loss, initial_weights, method=method, bounds=bounds, constraints=constraints)\n",
    "#         elif method in ['L-BFGS-B', 'TNC']:\n",
    "#             res = minimize(mse_loss, initial_weights, method=method, bounds=bounds)\n",
    "#         else:\n",
    "#             # For unconstrained methods, weights will be normalized in mse_loss\n",
    "#             res = minimize(mse_loss, initial_weights, method=method)\n",
    "#         if res.fun < best_mse:\n",
    "#             best_mse = res.fun\n",
    "#             best_weights = res.x / np.sum(res.x)  # Normalize weights\n",
    "#             best_method = method\n",
    "#         print(f\"Method: {method}, MSE: {res.fun}\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"Method: {method}, failed with error: {e}\")\n",
    "\n",
    "# # Average test predictions over folds for each model\n",
    "# for model_name in models:\n",
    "#     test_preds[model_name] = np.mean(test_preds[model_name], axis=2)  # Average over folds\n",
    "\n",
    "# # Combine the test predictions using the best weights\n",
    "# final_test_pred = np.zeros((X_test.shape[0], targets.shape[1]))\n",
    "# for i, model_name in enumerate(models):\n",
    "#     final_test_pred += best_weights[i] * test_preds[model_name]\n",
    "\n",
    "# # Create a DataFrame with IDs and predictions\n",
    "# prediction_df = pd.DataFrame({\n",
    "#     'ID': test_final['ID'],\n",
    "#     'longitude_predicted': final_test_pred[:, 1],\n",
    "#     'latitude_predicted': final_test_pred[:, 0]\n",
    "# })\n",
    "\n",
    "# # Save the predictions to a CSV file\n",
    "# prediction_df.to_csv('/Users/minasjovik/Projects/machine-learning-project/A-laget-ML-bajas/solutions/Mina/predictions11.csv', index=False)\n",
    "\n",
    "# # Print the best method and weights\n",
    "# print(f\"Best optimization method: {best_method}\")\n",
    "# print(\"Best weights:\")\n",
    "# for i, model_name in enumerate(models):\n",
    "#     print(f\"{model_name}: {best_weights[i]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vesselId          object\n",
      "target_lat       float64\n",
      "target_lon       float64\n",
      "target_time       object\n",
      "time_measured    float64\n",
      "lat_0            float64\n",
      "lon_0            float64\n",
      "lat_1            float64\n",
      "lon_1            float64\n",
      "dtype: object\n",
      "Index(['lat_0', 'lon_0', 'lat_1', 'lon_1'], dtype='object')\n",
      "Training and predicting with model: RandomForest\n",
      "Training and predicting with model: XGBoost\n",
      "Training and predicting with model: ElasticNet\n",
      "Training and predicting with model: LightGBM\n",
      "Training and predicting with model: RandomForest\n",
      "Training and predicting with model: XGBoost\n",
      "Training and predicting with model: ElasticNet\n",
      "Training and predicting with model: LightGBM\n",
      "Training and predicting with model: RandomForest\n",
      "Training and predicting with model: XGBoost\n",
      "Training and predicting with model: ElasticNet\n",
      "Training and predicting with model: LightGBM\n",
      "Training and predicting with model: RandomForest\n",
      "Training and predicting with model: XGBoost\n",
      "Training and predicting with model: ElasticNet\n",
      "Training and predicting with model: LightGBM\n",
      "Training and predicting with model: RandomForest\n",
      "Training and predicting with model: XGBoost\n",
      "Training and predicting with model: ElasticNet\n",
      "Training and predicting with model: LightGBM\n",
      "Optimizing weights using method: Nelder-Mead\n",
      "Method: Nelder-Mead, MSE: 597.1793759207427\n",
      "Optimizing weights using method: Powell\n",
      "Method: Powell, MSE: 597.1793779273958\n",
      "Optimizing weights using method: CG\n",
      "Method: CG, MSE: 597.1793759206076\n",
      "Optimizing weights using method: BFGS\n",
      "Method: BFGS, MSE: 597.1793759210904\n",
      "Optimizing weights using method: L-BFGS-B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/minasjovik/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/_minimize.py:541: RuntimeWarning: Method L-BFGS-B cannot handle constraints.\n",
      "  warn('Method %s cannot handle constraints.' % method,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: L-BFGS-B, MSE: 597.1793760909342\n",
      "Optimizing weights using method: TNC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/minasjovik/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/_minimize.py:541: RuntimeWarning: Method TNC cannot handle constraints.\n",
      "  warn('Method %s cannot handle constraints.' % method,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: TNC, MSE: 597.1794024941654\n",
      "Optimizing weights using method: SLSQP\n",
      "Method: SLSQP, MSE: 597.1793761708374\n",
      "Best optimization method: CG\n",
      "Best weights:\n",
      "RandomForest: 0.0127\n",
      "XGBoost: 0.2367\n",
      "ElasticNet: 0.4497\n",
      "LightGBM: 0.3010\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import ElasticNet\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "# Load the data\n",
    "test_final = pd.read_csv('/Users/minasjovik/Projects/machine-learning-project/A-laget-ML-bajas/solutions/Mina/processed_test.csv')\n",
    "final_train = pd.read_csv('/Users/minasjovik/Projects/machine-learning-project/A-laget-ML-bajas/solutions/Mina/processed_train_mina.csv')\n",
    "\n",
    "# Sort the training data by 'time_measured' to ensure chronological order\n",
    "final_train = final_train.sort_values(by='time_measured').reset_index(drop=True)\n",
    "print(final_train.dtypes)\n",
    "\n",
    "# Define features and targets\n",
    "features = final_train.drop(columns=['target_lat', 'target_lon', 'vesselId', 'time_measured', 'target_time'])\n",
    "targets = final_train[['target_lat', 'target_lon']]\n",
    "\n",
    "feature_columns = features.columns\n",
    "print(feature_columns)\n",
    "X_test = test_final[feature_columns]\n",
    "\n",
    "# Define the models\n",
    "models = {\n",
    "    'RandomForest': MultiOutputRegressor(RandomForestRegressor(n_estimators=100, random_state=42, max_depth=4, n_jobs=8)),\n",
    "    'XGBoost': MultiOutputRegressor(xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, seed=42)),\n",
    "    'ElasticNet': MultiOutputRegressor(ElasticNet(random_state=42)),\n",
    "    'LightGBM': MultiOutputRegressor(lgb.LGBMRegressor(n_estimators=100, random_state=42, verbose=-1))\n",
    "}\n",
    "\n",
    "# Prepare arrays to hold OOF predictions and test predictions\n",
    "n_splits = 5\n",
    "tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "\n",
    "oof_preds = {model_name: np.zeros((features.shape[0], targets.shape[1])) for model_name in models}\n",
    "test_preds = {model_name: np.zeros((X_test.shape[0], targets.shape[1], n_splits)) for model_name in models}\n",
    "\n",
    "# Perform time series cross-validation and collect predictions\n",
    "for fold, (train_idx, valid_idx) in enumerate(tscv.split(features, targets)):\n",
    "    X_train, y_train = features.iloc[train_idx], targets.iloc[train_idx]\n",
    "    X_valid, y_valid = features.iloc[valid_idx], targets.iloc[valid_idx]\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "        print(f\"Training and predicting with model: {model_name}\")\n",
    "        clf = model\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred_valid = clf.predict(X_valid)\n",
    "        y_pred_test = clf.predict(X_test)\n",
    "      \n",
    "        # Save OOF predictions\n",
    "        oof_preds[model_name][valid_idx] = y_pred_valid\n",
    "        # Save test predictions\n",
    "        test_preds[model_name][:,:,fold] = y_pred_test\n",
    "\n",
    "# Define the loss function for optimization\n",
    "def mse_loss(weights):\n",
    "    weights = np.array(weights)\n",
    "    # Normalize weights to sum to 1\n",
    "    weights = weights / np.sum(weights)\n",
    "    # Combine OOF predictions using the weights\n",
    "    final_oof = np.zeros_like(targets.values)\n",
    "    for i, model_name in enumerate(models):\n",
    "        final_oof += weights[i] * oof_preds[model_name]\n",
    "    # Compute mean squared error\n",
    "    mse = mean_squared_error(targets.values, final_oof)\n",
    "    return mse\n",
    "\n",
    "# Optimization methods to try\n",
    "methods = [\n",
    "    'Nelder-Mead', 'Powell',  'CG', 'BFGS',\n",
    "    'L-BFGS-B', 'TNC', 'SLSQP', \n",
    "]\n",
    "\n",
    "# Initial weights\n",
    "initial_weights = np.ones(len(models)) / len(models)\n",
    "\n",
    "# Constraints and bounds\n",
    "constraints = ({'type': 'eq', 'fun': lambda w: np.sum(w) - 1})\n",
    "bounds = [(0, 1)] * len(models)\n",
    "\n",
    "# Optimize weights using different methods\n",
    "best_mse = np.inf\n",
    "best_weights = None\n",
    "best_method = None\n",
    "\n",
    "for method in methods:\n",
    "    print(f\"Optimizing weights using method: {method}\")\n",
    "    try:\n",
    "        if method in ['SLSQP', 'TNC', 'L-BFGS-B']:\n",
    "            res = minimize(mse_loss, initial_weights, method=method, bounds=bounds, constraints=constraints)\n",
    "        else:\n",
    "            # For unconstrained methods, weights will be normalized in mse_loss\n",
    "            res = minimize(mse_loss, initial_weights, method=method)\n",
    "        if res.fun < best_mse:\n",
    "            best_mse = res.fun\n",
    "            best_weights = res.x / np.sum(res.x)  # Normalize weights\n",
    "            best_method = method\n",
    "        print(f\"Method: {method}, MSE: {res.fun}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Method: {method}, failed with error: {e}\")\n",
    "\n",
    "# Average test predictions over folds for each model\n",
    "for model_name in models:\n",
    "    test_preds[model_name] = np.mean(test_preds[model_name], axis=2)  # Average over folds\n",
    "\n",
    "# Combine the test predictions using the best weights\n",
    "final_test_pred = np.zeros((X_test.shape[0], targets.shape[1]))\n",
    "for i, model_name in enumerate(models):\n",
    "    final_test_pred += best_weights[i] * test_preds[model_name]\n",
    "\n",
    "# Create a DataFrame with IDs and predictions\n",
    "prediction_df = pd.DataFrame({\n",
    "    'ID': test_final['ID'],\n",
    "    'longitude_predicted': final_test_pred[:, 1],\n",
    "    'latitude_predicted': final_test_pred[:, 0]\n",
    "})\n",
    "\n",
    "# Save the predictions to a CSV file\n",
    "prediction_df.to_csv('/Users/minasjovik/Projects/machine-learning-project/A-laget-ML-bajas/solutions/Mina/predictions12.csv', index=False)\n",
    "\n",
    "# Print the best method and weights\n",
    "print(f\"Best optimization method: {best_method}\")\n",
    "print(\"Best weights:\")\n",
    "for i, model_name in enumerate(models):\n",
    "    print(f\"{model_name}: {best_weights[i]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         vessel_size  yearBuilt  minutes_from_target_0  heading_0     lat_0  \\\n",
      "0             6368.0       2000             107.016667        316   7.50361   \n",
      "1             6368.0       2000             103.983333        313   7.57302   \n",
      "2             6368.0       2000              98.016667        312   7.65043   \n",
      "3             6368.0       2000              96.600000        313   7.71275   \n",
      "4             6368.0       2000              94.816667        313   7.77191   \n",
      "...              ...        ...                    ...        ...       ...   \n",
      "1518624       4966.0       2017              97.083333        289  59.46124   \n",
      "1518625       4966.0       2017              97.783333        291  59.48803   \n",
      "1518626       4966.0       2017              98.016667        294  59.51857   \n",
      "1518627       4966.0       2017             103.333333        295  59.54180   \n",
      "1518628       4966.0       2017             103.733333        298  59.57721   \n",
      "\n",
      "            lon_0  minutes_from_target_1  heading_1     lat_1     lon_1  ...  \\\n",
      "0        77.58340              83.800000        313   7.57302  77.49505  ...   \n",
      "1        77.49505              77.600000        312   7.65043  77.39404  ...   \n",
      "2        77.39404              76.600000        313   7.71275  77.31394  ...   \n",
      "3        77.31394              75.616667        313   7.77191  77.23585  ...   \n",
      "4        77.23585              79.800000        313   7.81285  77.18147  ...   \n",
      "...           ...                    ...        ...       ...       ...  ...   \n",
      "1518624  22.12378              76.966667        291  59.48803  21.96346  ...   \n",
      "1518625  21.96346              77.200000        294  59.51857  21.80145  ...   \n",
      "1518626  21.80145              83.016667        295  59.54180  21.68877  ...   \n",
      "1518627  21.68877              82.933333        298  59.57721  21.54090  ...   \n",
      "1518628  21.54090              82.750000        325  59.63337  21.43237  ...   \n",
      "\n",
      "            lat_2     lon_2  minutes_from_target_3  heading_3     lat_3  \\\n",
      "0         7.65043  77.39404              36.000000        313   7.71275   \n",
      "1         7.71275  77.31394              35.200000        313   7.77191   \n",
      "2         7.77191  77.23585              40.600000        313   7.81285   \n",
      "3         7.81285  77.18147              40.416667        313   7.86929   \n",
      "4         7.86929  77.11032              39.200000        311   7.92585   \n",
      "...           ...       ...                    ...        ...       ...   \n",
      "1518624  59.51857  21.80145              41.383333        295  59.54180   \n",
      "1518625  59.54180  21.68877              41.800000        298  59.57721   \n",
      "1518626  59.57721  21.54090              41.633333        325  59.63337   \n",
      "1518627  59.63337  21.43237              41.133333        326  59.69588   \n",
      "1518628  59.69588  21.34225              41.116667        354  59.76388   \n",
      "\n",
      "            lon_3  minutes_from_target_4  heading_4     lat_4     lon_4  \n",
      "0        77.31394              15.016667        313   7.77191  77.23585  \n",
      "1        77.23585              20.183333        313   7.81285  77.18147  \n",
      "2        77.18147              20.416667        313   7.86929  77.11032  \n",
      "3        77.11032              20.000000        311   7.92585  77.03811  \n",
      "4        77.03811              19.200000        311   7.98258  76.96880  \n",
      "...           ...                    ...        ...       ...       ...  \n",
      "1518624  21.68877              20.983333        298  59.57721  21.54090  \n",
      "1518625  21.54090              20.816667        325  59.63337  21.43237  \n",
      "1518626  21.43237              20.816667        326  59.69588  21.34225  \n",
      "1518627  21.34225              20.316667        354  59.76388  21.35317  \n",
      "1518628  21.35317              20.800000         50  59.83316  21.38489  \n",
      "\n",
      "[1518629 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = '/Users/minasjovik/Projects/machine-learning-project/A-laget-ML-bajas/solutions/Mina/predictions13.csv'\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "df = pd.read_csv('/Users/minasjovik/Projects/machine-learning-project/A-laget-ML-bajas/solutions/Mina/predictions12.csv')\n",
    "\n",
    "# Ensure the 'ID' column exists in the DataFrame\n",
    "if 'ID' in df.columns:\n",
    "    # Remove decimals in the 'ID' column by converting to integers\n",
    "    # This will truncate the decimal part\n",
    "    df['ID'] = df['ID'].astype(int)\n",
    "    \n",
    "    # Alternatively, if you want to round the 'ID' values\n",
    "    # df['ID'] = df['ID'].round().astype(int)\n",
    "else:\n",
    "    print(\"The 'ID' column is not found in the CSV file.\")\n",
    "    # Optionally, you can exit the script or handle the error as needed\n",
    "    # exit()\n",
    "\n",
    "# Sort the DataFrame by the 'ID' column\n",
    "df = df.sort_values(by='ID')\n",
    "\n",
    "# Reset the index if desired\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# Save the modified DataFrame to a new CSV file\n",
    "df.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maskinlaering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
